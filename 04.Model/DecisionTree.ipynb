{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('Data_drop_year.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Time</th>\n",
       "      <th>Store</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jenae K.</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>Amazon Go</td>\n",
       "      <td>store awesome super cool concept definitley se...</td>\n",
       "      <td>[\" 'data integration'\", \" 'marketing and commu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jenae K.</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>Amazon Go</td>\n",
       "      <td>scan app enter store grab whatever want shelf ...</td>\n",
       "      <td>[\" 'technology'\", \" 'payment and checkout'\"]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jenae K.</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>Amazon Go</td>\n",
       "      <td>product shelf sensor know grab item</td>\n",
       "      <td>[\" 'technology'\"]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jenae K.</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>Amazon Go</td>\n",
       "      <td>crazy no cashier no line</td>\n",
       "      <td>[\" 'payment and checkout'\"]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jenae K.</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>Amazon Go</td>\n",
       "      <td>super simple course still worker ensure entran...</td>\n",
       "      <td>[\" 'technology'\", \" 'shopping experience'\", \" ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87635</th>\n",
       "      <td>Melissa C.</td>\n",
       "      <td>2020-08-09</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>time worth stop come unless</td>\n",
       "      <td>[\" 'price and value'\"]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87636</th>\n",
       "      <td>Mark H.</td>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>lose shipment twice row delay order two week s...</td>\n",
       "      <td>[\" 'technology'\", \" 'unemployment'\"]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87637</th>\n",
       "      <td>Mark H.</td>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>call refund tell would take day get money back</td>\n",
       "      <td>[\" 'price and value'\", \" 'payment and checkout'\"]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87638</th>\n",
       "      <td>Lorna B.</td>\n",
       "      <td>2021-09-09</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>far too many grocery available store not avail...</td>\n",
       "      <td>[\" 'technology'\", \" 'general'\"]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87639</th>\n",
       "      <td>NATISHA J.</td>\n",
       "      <td>2021-09-09</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>place need walmart lead sell good merchandise ...</td>\n",
       "      <td>[\" 'shopping experience'\"]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87640 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name        Time      Store  \\\n",
       "0        Jenae K.  2018-06-01  Amazon Go   \n",
       "1        Jenae K.  2018-06-01  Amazon Go   \n",
       "2        Jenae K.  2018-06-01  Amazon Go   \n",
       "3        Jenae K.  2018-06-01  Amazon Go   \n",
       "4        Jenae K.  2018-06-01  Amazon Go   \n",
       "...           ...         ...        ...   \n",
       "87635  Melissa C.  2020-08-09    Walmart   \n",
       "87636     Mark H.  2020-09-09    Walmart   \n",
       "87637     Mark H.  2020-09-09    Walmart   \n",
       "87638    Lorna B.  2021-09-09    Walmart   \n",
       "87639  NATISHA J.  2021-09-09    Walmart   \n",
       "\n",
       "                                                 Comment  \\\n",
       "0      store awesome super cool concept definitley se...   \n",
       "1      scan app enter store grab whatever want shelf ...   \n",
       "2                    product shelf sensor know grab item   \n",
       "3                               crazy no cashier no line   \n",
       "4      super simple course still worker ensure entran...   \n",
       "...                                                  ...   \n",
       "87635                        time worth stop come unless   \n",
       "87636  lose shipment twice row delay order two week s...   \n",
       "87637     call refund tell would take day get money back   \n",
       "87638  far too many grocery available store not avail...   \n",
       "87639  place need walmart lead sell good merchandise ...   \n",
       "\n",
       "                                                  Aspect  polarity  \n",
       "0      [\" 'data integration'\", \" 'marketing and commu...  positive  \n",
       "1           [\" 'technology'\", \" 'payment and checkout'\"]  positive  \n",
       "2                                      [\" 'technology'\"]   neutral  \n",
       "3                            [\" 'payment and checkout'\"]  negative  \n",
       "4      [\" 'technology'\", \" 'shopping experience'\", \" ...  positive  \n",
       "...                                                  ...       ...  \n",
       "87635                             [\" 'price and value'\"]  negative  \n",
       "87636               [\" 'technology'\", \" 'unemployment'\"]  negative  \n",
       "87637  [\" 'price and value'\", \" 'payment and checkout'\"]   neutral  \n",
       "87638                    [\" 'technology'\", \" 'general'\"]   neutral  \n",
       "87639                         [\" 'shopping experience'\"]  positive  \n",
       "\n",
       "[87640 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.6484481971702419\n"
     ]
    }
   ],
   "source": [
    "# build a random forest model to predict the aspect of the comment\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# split data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Comment'], df['Aspect'], test_size=0.2, random_state=0)\n",
    "\n",
    "# build a logistic regression model with glove embedding\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# build a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "# train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# predict the aspect of the comment\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "print('accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to predict aspect of the comment\n",
    "def predict_aspect(comment):\n",
    "    # remove punctuation\n",
    "    comment = ''.join([char for char in comment if char not in string.punctuation])\n",
    "    # predict the aspect\n",
    "    return pipeline.predict([comment])[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predict_aspect(\u001b[39m'\u001b[39;49m\u001b[39muuyurwe\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn [5], line 6\u001b[0m, in \u001b[0;36mpredict_aspect\u001b[1;34m(comment)\u001b[0m\n\u001b[0;32m      4\u001b[0m comment \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([char \u001b[39mfor\u001b[39;00m char \u001b[39min\u001b[39;00m comment \u001b[39mif\u001b[39;00m char \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m string\u001b[39m.\u001b[39mpunctuation])\n\u001b[0;32m      5\u001b[0m \u001b[39m# predict the aspect\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mreturn\u001b[39;00m pipeline\u001b[39m.\u001b[39mpredict([comment])[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "predict_aspect('uuyurwe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to predict the aspect of the comment\n",
    "def predict_aspect(comment):\n",
    "    # preprocess the comment\n",
    "    # remove punctuation\n",
    "    comment = comment.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # remove stop words\n",
    "    comment = ' '.join([word for word in comment.split() if word not in stop])\n",
    "\n",
    "    # remove digits\n",
    "    comment = ''.join([i for i in comment if not i.isdigit()])\n",
    "\n",
    "    # remove white space\n",
    "    comment = ' '.join(comment.split())\n",
    "\n",
    "    # convert to lower case\n",
    "    comment = comment.lower()\n",
    "\n",
    "    # predict the aspect of the comment\n",
    "    return pipeline.predict([comment])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predict_aspect(\u001b[39m'\u001b[39;49m\u001b[39mpayment is very fast\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn [2], line 8\u001b[0m, in \u001b[0;36mpredict_aspect\u001b[1;34m(comment)\u001b[0m\n\u001b[0;32m      5\u001b[0m comment \u001b[39m=\u001b[39m comment\u001b[39m.\u001b[39mtranslate(\u001b[39mstr\u001b[39m\u001b[39m.\u001b[39mmaketrans(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, string\u001b[39m.\u001b[39mpunctuation))\n\u001b[0;32m      7\u001b[0m \u001b[39m# remove stop words\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m comment \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([word \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m comment\u001b[39m.\u001b[39msplit() \u001b[39mif\u001b[39;00m word \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop])\n\u001b[0;32m     10\u001b[0m \u001b[39m# remove digits\u001b[39;00m\n\u001b[0;32m     11\u001b[0m comment \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m comment \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m i\u001b[39m.\u001b[39misdigit()])\n",
      "Cell \u001b[1;32mIn [2], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m comment \u001b[39m=\u001b[39m comment\u001b[39m.\u001b[39mtranslate(\u001b[39mstr\u001b[39m\u001b[39m.\u001b[39mmaketrans(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, string\u001b[39m.\u001b[39mpunctuation))\n\u001b[0;32m      7\u001b[0m \u001b[39m# remove stop words\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m comment \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([word \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m comment\u001b[39m.\u001b[39msplit() \u001b[39mif\u001b[39;00m word \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop])\n\u001b[0;32m     10\u001b[0m \u001b[39m# remove digits\u001b[39;00m\n\u001b[0;32m     11\u001b[0m comment \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m comment \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m i\u001b[39m.\u001b[39misdigit()])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "predict_aspect('payment is very fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predict_aspect(\u001b[39m'\u001b[39;49m\u001b[39mI love how those AI cameras can detect faces and objects\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn [7], line 8\u001b[0m, in \u001b[0;36mpredict_aspect\u001b[1;34m(comment)\u001b[0m\n\u001b[0;32m      5\u001b[0m comment \u001b[39m=\u001b[39m comment\u001b[39m.\u001b[39mtranslate(\u001b[39mstr\u001b[39m\u001b[39m.\u001b[39mmaketrans(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, string\u001b[39m.\u001b[39mpunctuation))\n\u001b[0;32m      7\u001b[0m \u001b[39m# remove stop words\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m comment \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([word \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m comment\u001b[39m.\u001b[39msplit() \u001b[39mif\u001b[39;00m word \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop])\n\u001b[0;32m     10\u001b[0m \u001b[39m# remove digits\u001b[39;00m\n\u001b[0;32m     11\u001b[0m comment \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m comment \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m i\u001b[39m.\u001b[39misdigit()])\n",
      "Cell \u001b[1;32mIn [7], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m comment \u001b[39m=\u001b[39m comment\u001b[39m.\u001b[39mtranslate(\u001b[39mstr\u001b[39m\u001b[39m.\u001b[39mmaketrans(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, string\u001b[39m.\u001b[39mpunctuation))\n\u001b[0;32m      7\u001b[0m \u001b[39m# remove stop words\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m comment \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([word \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m comment\u001b[39m.\u001b[39msplit() \u001b[39mif\u001b[39;00m word \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop])\n\u001b[0;32m     10\u001b[0m \u001b[39m# remove digits\u001b[39;00m\n\u001b[0;32m     11\u001b[0m comment \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m comment \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m i\u001b[39m.\u001b[39misdigit()])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "predict_aspect('I love how those AI cameras can detect faces and objects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"['']\", \"['']\", \"['', 'technology', 'payment and checkout']\", ...,\n",
       "       \"['', 'shopping experience']\",\n",
       "       \"['', 'technology', 'payment and checkout']\", \"['']\"], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train test sets to predictr the polarity of the comment\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Comment'], df['polarity'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8967458726977765\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# predict the polarity of the comment\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "print('accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.80      0.83     10414\n",
      "     neutral       0.92      0.98      0.95     18801\n",
      "    positive       0.88      0.86      0.87     12701\n",
      "\n",
      "    accuracy                           0.90     41916\n",
      "   macro avg       0.89      0.88      0.88     41916\n",
      "weighted avg       0.90      0.90      0.90     41916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print report of the model\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8317   850  1247]\n",
      " [  203 18363   235]\n",
      " [ 1106   687 10908]]\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5addf786bcd861d1ce5006f23111f8cbb206731e5b61b0a5632ba9e0252558a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
